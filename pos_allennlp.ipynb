{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример работы с allennlp\n",
    "Здесь мы разберем аналогичную модель, что мы писали на торче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src_allennlp.model import SimpleTagger\n",
    "from src_allennlp.reader import RuPosReader\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.common import Params\n",
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.modules.seq2seq_encoders import PytorchSeq2SeqWrapper\n",
    "from allennlp.data.iterators import BucketIterator\n",
    "from allennlp.training.trainer import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из всех импортов тут только два самописных класса - ридер и, собственно, сама модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48171it [00:03, 12951.79it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 48171/48171 [00:00<00:00, 52064.41it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 2000000/2000000 [00:15<00:00, 127662.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary with namespaces:\n",
      " \tNon Padded Namespaces: {'*labels', '*tags'}\n",
      " \tNamespace: tokens, Size: 98882 \n",
      " \tNamespace: labels, Size: 17 \n",
      "\n",
      "{0: 'NOUN', 1: 'PUNCT', 2: 'VERB', 3: 'ADJ', 4: 'ADP', 5: 'ADV', 6: 'PROPN', 7: 'PRON', 8: 'CONJ', 9: 'PART', 10: 'DET', 11: 'SCONJ', 12: 'NUM', 13: 'AUX', 14: 'X', 15: 'INTJ', 16: 'SYM'}\n"
     ]
    }
   ],
   "source": [
    "reader = RuPosReader()\n",
    "dataset = reader.read('data/train.csv')\n",
    "vocab = Vocabulary.from_instances(dataset, pretrained_files={'tokens':'data/cc.ru.300.vec'}, only_include_pretrained_words=False)\n",
    "print(vocab)\n",
    "print(vocab.get_index_to_token_vocabulary('labels'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ячейке выше мы прочитали датасет и сделали из него словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 2000000/2000000 [00:26<00:00, 76039.26it/s]\n"
     ]
    }
   ],
   "source": [
    "word_emb = 300\n",
    "hidden_dim = 300\n",
    "\n",
    "params = Params({\"pretrained_file\": 'data/cc.ru.300.vec', \"embedding_dim\": word_emb, \"trainable\": False})\n",
    "embedder = BasicTextFieldEmbedder({\"tokens\": Embedding.from_params(vocab, params)})\n",
    "encoder = PytorchSeq2SeqWrapper(torch.nn.GRU(embedder.get_output_dim(), hidden_dim, batch_first=True, bidirectional=True, num_layers=2))\n",
    "model = SimpleTagger(vocab, embedder, encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша модель состоит из:\n",
    "- эмбеддера, возвращающего векторные представления для каждого токена\n",
    "- энкодера, который представляет собой всё ту же GRU, как и раньше, только всякими неудобными вещами занимется `PytorchSeq2SeqWrapper`.\n",
    "- FeedForward, который уже встроен в модель, но его можно и передать отдельно, предварительно поддержав в самой модели в конструкторе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[:-1000]\n",
    "dev_dataset = dataset[-1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распиливаем датасет, слайсы здесь работают нормально"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "iterator = BucketIterator(batch_size=256, sorting_keys=[(\"tokens\", \"num_tokens\")], biggest_batch_first=True)\n",
    "iterator.index_with(vocab)\n",
    "trainer = Trainer(model=model,\n",
    "                  optimizer=optimizer,\n",
    "                  iterator=iterator,\n",
    "                  train_dataset=train_dataset,\n",
    "                  validation_dataset=dev_dataset,\n",
    "                  patience=5,\n",
    "                  num_epochs=20,\n",
    "                  cuda_device=0,\n",
    "                  validation_metric=\"+fscore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переносим модель на видеокарту, задаём оптимизатор, итератор с индексированием по словарю и сам тренер. У тренера есть куча удобных параметров, например, сколько эпох учить, через сколько эпох остановиться, если таргетная метрика перестаёт расти на валидации (`patience`) и собственно сама таргетная метрика, по которой будет выбираться лучшая эпоха"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7411, precision: 0.7411, recall: 0.7411, fscore: 0.7411, loss: 0.8184 ||: 100%|█| 185/185 [00:13<00:00, 13.\n",
      "accuracy: 0.9293, precision: 0.9293, recall: 0.9293, fscore: 0.9293, loss: 0.2344 ||: 100%|█| 4/4 [00:00<00:00, 23.73it\n",
      "accuracy: 0.9436, precision: 0.9436, recall: 0.9436, fscore: 0.9436, loss: 0.1905 ||: 100%|█| 185/185 [00:11<00:00, 16.\n",
      "accuracy: 0.9540, precision: 0.9540, recall: 0.9540, fscore: 0.9540, loss: 0.1566 ||: 100%|█| 4/4 [00:00<00:00, 29.06it\n",
      "accuracy: 0.9560, precision: 0.9560, recall: 0.9560, fscore: 0.9560, loss: 0.1469 ||: 100%|█| 185/185 [00:11<00:00, 16.\n",
      "accuracy: 0.9635, precision: 0.9635, recall: 0.9635, fscore: 0.9635, loss: 0.1276 ||: 100%|█| 4/4 [00:00<00:00, 29.93it\n",
      "accuracy: 0.9614, precision: 0.9614, recall: 0.9614, fscore: 0.9614, loss: 0.1262 ||: 100%|█| 185/185 [00:11<00:00, 16.\n",
      "accuracy: 0.9665, precision: 0.9665, recall: 0.9665, fscore: 0.9665, loss: 0.1163 ||: 100%|█| 4/4 [00:00<00:00, 29.93it\n",
      "accuracy: 0.9652, precision: 0.9652, recall: 0.9652, fscore: 0.9652, loss: 0.1120 ||: 100%|█| 185/185 [00:11<00:00, 16.\n",
      "accuracy: 0.9693, precision: 0.9693, recall: 0.9693, fscore: 0.9693, loss: 0.1048 ||: 100%|█| 4/4 [00:00<00:00, 30.15it\n",
      "accuracy: 0.9684, precision: 0.9684, recall: 0.9684, fscore: 0.9684, loss: 0.1001 ||: 100%|█| 185/185 [00:11<00:00, 16.\n",
      "accuracy: 0.9716, precision: 0.9716, recall: 0.9716, fscore: 0.9716, loss: 0.0979 ||: 100%|█| 4/4 [00:00<00:00, 30.50it\n",
      "accuracy: 0.9707, precision: 0.9707, recall: 0.9707, fscore: 0.9707, loss: 0.0921 ||: 100%|█| 185/185 [00:11<00:00, 16.\n",
      "accuracy: 0.9745, precision: 0.9745, recall: 0.9745, fscore: 0.9745, loss: 0.0886 ||: 100%|█| 4/4 [00:00<00:00, 29.93it\n",
      "accuracy: 0.9730, precision: 0.9730, recall: 0.9730, fscore: 0.9730, loss: 0.0831 ||: 100%|█| 185/185 [00:11<00:00, 16.\n",
      "accuracy: 0.9745, precision: 0.9745, recall: 0.9745, fscore: 0.9745, loss: 0.0845 ||: 100%|█| 4/4 [00:00<00:00, 30.15it\n",
      "accuracy: 0.9747, precision: 0.9747, recall: 0.9747, fscore: 0.9747, loss: 0.0761 ||: 100%|█| 185/185 [00:11<00:00, 16.\n",
      "accuracy: 0.9759, precision: 0.9759, recall: 0.9759, fscore: 0.9759, loss: 0.0825 ||: 100%|█| 4/4 [00:00<00:00, 29.71it\n",
      "accuracy: 0.9767, precision: 0.9767, recall: 0.9767, fscore: 0.9767, loss: 0.0698 ||: 100%|█| 185/185 [00:11<00:00, 16.\n",
      "accuracy: 0.9757, precision: 0.9757, recall: 0.9757, fscore: 0.9757, loss: 0.0805 ||: 100%|█| 4/4 [00:00<00:00, 29.38it\n",
      "accuracy: 0.9782, precision: 0.9782, recall: 0.9782, fscore: 0.9782, loss: 0.0636 ||: 100%|█| 185/185 [00:11<00:00, 16.\n",
      "accuracy: 0.9768, precision: 0.9768, recall: 0.9768, fscore: 0.9768, loss: 0.0804 ||: 100%|█| 4/4 [00:00<00:00, 30.68it\n",
      "accuracy: 0.9802, precision: 0.9802, recall: 0.9802, fscore: 0.9802, loss: 0.0567 ||: 100%|█| 185/185 [00:11<00:00, 16.\n",
      "accuracy: 0.9763, precision: 0.9763, recall: 0.9763, fscore: 0.9763, loss: 0.0788 ||: 100%|█| 4/4 [00:00<00:00, 29.82it\n",
      "accuracy: 0.9811, precision: 0.9811, recall: 0.9811, fscore: 0.9811, loss: 0.0524 ||: 100%|█| 185/185 [00:11<00:00, 16.\n",
      "accuracy: 0.9772, precision: 0.9772, recall: 0.9772, fscore: 0.9772, loss: 0.0771 ||: 100%|█| 4/4 [00:00<00:00, 29.49it\n",
      "accuracy: 0.9827, precision: 0.9827, recall: 0.9827, fscore: 0.9827, loss: 0.0472 ||: 100%|█| 185/185 [00:11<00:00, 16.\n",
      "accuracy: 0.9771, precision: 0.9771, recall: 0.9771, fscore: 0.9771, loss: 0.0788 ||: 100%|█| 4/4 [00:00<00:00, 29.49it\n",
      "accuracy: 0.9847, precision: 0.9847, recall: 0.9847, fscore: 0.9847, loss: 0.0411 ||: 100%|█| 185/185 [00:11<00:00, 16.\n",
      "accuracy: 0.9776, precision: 0.9776, recall: 0.9776, fscore: 0.9776, loss: 0.0814 ||: 100%|█| 4/4 [00:00<00:00, 30.62it\n",
      "accuracy: 0.9860, precision: 0.9860, recall: 0.9860, fscore: 0.9860, loss: 0.0363 ||: 100%|█| 185/185 [00:11<00:00, 16.\n",
      "accuracy: 0.9774, precision: 0.9774, recall: 0.9774, fscore: 0.9774, loss: 0.0834 ||: 100%|█| 4/4 [00:00<00:00, 29.27it\n",
      "accuracy: 0.9875, precision: 0.9875, recall: 0.9875, fscore: 0.9875, loss: 0.0318 ||: 100%|█| 185/185 [00:11<00:00, 16.\n",
      "accuracy: 0.9780, precision: 0.9780, recall: 0.9780, fscore: 0.9780, loss: 0.0859 ||: 100%|█| 4/4 [00:00<00:00, 29.93it\n",
      "accuracy: 0.9894, precision: 0.9894, recall: 0.9894, fscore: 0.9894, loss: 0.0262 ||: 100%|█| 185/185 [00:11<00:00, 16.\n",
      "accuracy: 0.9784, precision: 0.9784, recall: 0.9784, fscore: 0.9784, loss: 0.0859 ||: 100%|█| 4/4 [00:00<00:00, 26.56it\n",
      "accuracy: 0.9902, precision: 0.9902, recall: 0.9902, fscore: 0.9902, loss: 0.0237 ||: 100%|█| 185/185 [00:11<00:00, 16.\n",
      "accuracy: 0.9776, precision: 0.9776, recall: 0.9776, fscore: 0.9776, loss: 0.0862 ||: 100%|█| 4/4 [00:00<00:00, 29.49it\n",
      "accuracy: 0.9918, precision: 0.9918, recall: 0.9918, fscore: 0.9918, loss: 0.0194 ||: 100%|█| 185/185 [00:11<00:00, 15.\n",
      "accuracy: 0.9777, precision: 0.9777, recall: 0.9777, fscore: 0.9777, loss: 0.0956 ||: 100%|█| 4/4 [00:00<00:00, 29.17it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_epoch': 17,\n",
       " 'peak_cpu_memory_MB': 0,\n",
       " 'training_duration': '0:03:52.182084',\n",
       " 'training_start_epoch': 0,\n",
       " 'training_epochs': 19,\n",
       " 'epoch': 19,\n",
       " 'training_accuracy': 0.9918004360780812,\n",
       " 'training_precision': 0.9918004274368286,\n",
       " 'training_recall': 0.9918004274368286,\n",
       " 'training_fscore': 0.9918004274368286,\n",
       " 'training_loss': 0.019412214443641336,\n",
       " 'training_cpu_memory_MB': 0.0,\n",
       " 'validation_accuracy': 0.9776970954356846,\n",
       " 'validation_precision': 0.9776970744132996,\n",
       " 'validation_recall': 0.9776970744132996,\n",
       " 'validation_fscore': 0.9776970744132996,\n",
       " 'validation_loss': 0.09564318507909775,\n",
       " 'best_validation_accuracy': 0.9783886583679114,\n",
       " 'best_validation_precision': 0.9783886671066284,\n",
       " 'best_validation_recall': 0.9783886671066284,\n",
       " 'best_validation_fscore': 0.9783886671066284,\n",
       " 'best_validation_loss': 0.08592475764453411}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После обучения модели остаётся только предстказать метки классов и можно заворачивать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "results = []\n",
    "with torch.no_grad():    \n",
    "    labels =  model.forward_on_instance(dev_dataset[1])['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сам по себе инстанс это что-то похожее на словарь, поэтому чтобы добраться до токенов, нужно немного пройти по словарю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сегодня ADV\n",
      "Великий ADJ\n",
      "Октябрь NOUN\n",
      "прибавил VERB\n",
      "к ADP\n",
      "своей DET\n",
      "биографии NOUN\n",
      "еще ADV\n",
      "один NUM\n",
      "год NOUN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token, label in zip(dev_dataset[1]['tokens'].tokens,labels):\n",
    "    print(token, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собственно вот и все. Allennlp прекрасен и очень удобен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
