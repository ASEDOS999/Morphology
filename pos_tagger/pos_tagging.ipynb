{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pd3J2HY_qH-j",
    "outputId": "1863363b-4dd3-40f8-f54a-4d92590d6cb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: conllu in /home/elias/anaconda3/lib/python3.7/site-packages (4.2.1)\r\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import re\n",
    "import time\n",
    "\n",
    "!pip install conllu\n",
    "import conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jhpBo-WmIo2M"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKjrEjE7bYsW"
   },
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1BxMlgmkKJo"
   },
   "source": [
    "За основу взята модель из статьи [Morphosyntactic Tagging with a Meta-BiLSTM Model over Context Sensitive Token Encodings](https://arxiv.org/pdf/1805.08237.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wTkFfZLR2Gye"
   },
   "outputs": [],
   "source": [
    "class Masking(nn.Module):\n",
    "  def __init__(self, list_of_characters, device):\n",
    "    self.chars = list(list_of_characters)\n",
    "    self.size_vocab = len(self.chars)\n",
    "    self.device = device\n",
    "  \n",
    "  def split_elem(self, input_string):\n",
    "    return [i for i in input_string]\n",
    "  \n",
    "  def mask_elem(self, input_string):\n",
    "    chars = self.split_elem(input_string)\n",
    "    res = np.zeros(len(input_string))\n",
    "    for ind, char in enumerate(chars):\n",
    "      try:\n",
    "        ind_char = self.chars.index(char)\n",
    "        res[ind] = ind_char\n",
    "      except:\n",
    "        ind_char = len(self.chars)\n",
    "    return torch.tensor(res).to(device).to(torch.int64)\n",
    "  \n",
    "  def mask_batch(self, strings):\n",
    "    res = []\n",
    "    for input_string in strings:\n",
    "      res += [self.mask_elem(input_string)]\n",
    "    return res\n",
    "  \n",
    "  def unmask_elem(self, ind_list):\n",
    "    out = \"\"\n",
    "    for ind in ind_list:\n",
    "      if ind < len(self.chars):\n",
    "        out += self.chars[int(ind)]\n",
    "    return out\n",
    "\n",
    "  def unmask_batch(self, input_lists):\n",
    "    res = []\n",
    "    for ind_list in input_lists:\n",
    "      res += [self.unmask_elem(ind_list)]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "pwkeY60k6HLx"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers,\n",
    "                 dropout=0.2,\n",
    "                 bidirectional=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = None\n",
    "        if emb_dim is not None:\n",
    "            self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "            self.rnn = nn.LSTM(emb_dim,\n",
    "                               hid_dim,\n",
    "                               n_layers,\n",
    "                               dropout=dropout,\n",
    "                               bidirectional=bidirectional)\n",
    "        else:\n",
    "            self.rnn = nn.LSTM(input_dim,\n",
    "                               hid_dim,\n",
    "                               n_layers,\n",
    "                               dropout=dropout,\n",
    "                               bidirectional=bidirectional)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        output = []\n",
    "        if self.embedding is not None:\n",
    "            for i in src:\n",
    "                output.append(self.dropout(self.embedding(i)))\n",
    "        else:\n",
    "            output = src\n",
    "        out = []\n",
    "        for i in output:\n",
    "            out.append(self.rnn(i.view(i.shape[0], 1, i.shape[-1]))[0])\n",
    "        return out\n",
    "\n",
    "    \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, out_dim, dimensions=[]):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.out_dim = out_dim\n",
    "        if dimensions is None:\n",
    "            dimensions = []\n",
    "        dimensions = [input_dim] + dimensions\n",
    "        layers = []\n",
    "        for ind, dim in enumerate(dimensions[:-1]):\n",
    "            layers.append(nn.Linear(dim, dimensions[ind+1]))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(dimensions[-1], out_dim))\n",
    "        self.seq = torch.nn.Sequential(*layers)\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "    def forward(self, src):\n",
    "        output = []\n",
    "        for i in range(len(src)):\n",
    "            cur_output = torch.zeros((src[i].shape[0], self.out_dim))\n",
    "            for j in range(len(src[i])):\n",
    "                cur_output[j] = self.seq(src[i][j])\n",
    "            output.append(cur_output)\n",
    "        return output\n",
    "\n",
    "    \n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, out_dim, n_layers,\n",
    "                 dropout=0.2,\n",
    "                 bidirectional=True, dimensions=[]):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(input_dim, emb_dim, hid_dim, n_layers,\n",
    "                               dropout=dropout,\n",
    "                               bidirectional=bidirectional)\n",
    "        if bidirectional:\n",
    "            input_dim_mlp = hid_dim * 2\n",
    "        else:\n",
    "            input_dim_mlp = hid_dim\n",
    "        self.mlp = MLP(input_dim_mlp, out_dim, dimensions)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        out = []\n",
    "        out = self.encoder(src)\n",
    "        out = self.mlp(out)\n",
    "        return out\n",
    "\n",
    "class BiLSTM_char(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, out_dim, n_layers,\n",
    "                 dropout=0.2,\n",
    "                 bidirectional=True, dimensions=[]):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(input_dim, emb_dim, hid_dim, n_layers,\n",
    "                               dropout=dropout,\n",
    "                               bidirectional=bidirectional)\n",
    "        if bidirectional:\n",
    "            input_dim_mlp = hid_dim * 4\n",
    "        else:\n",
    "            input_dim_mlp = hid_dim * 2\n",
    "        self.mlp = MLP(input_dim_mlp, out_dim, dimensions)\n",
    "        \n",
    "    def forward(self, src, split_into_words):\n",
    "        out = self.encoder(src)\n",
    "        out_split = []\n",
    "        for i in range(len(src)):\n",
    "            cur_split = split_into_words[i]\n",
    "            cur = torch.zeros((len(cur_split), out[i].shape[2] * 2))\n",
    "            for ind, (start, end) in enumerate(cur_split):\n",
    "                cur[ind] = torch.cat([out[i][start], out[i][end-1]], dim=1)\n",
    "            out_split.append(cur)\n",
    "        out = self.mlp(out_split)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MetaBiLSTM(nn.Module):\n",
    "    def __init__(self, char_model, word_model, meta):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.char_model = char_model\n",
    "        self.word_model = word_model\n",
    "        self.meta = meta\n",
    "        \n",
    "    def forward(self, src):\n",
    "        pos_w = self.word_model(src[2])\n",
    "        pos_c = self.char_model(src[0], src[1])\n",
    "        inp = [torch.cat([pos_c[ind], i], dim=-1) for ind, i in enumerate(pos_w)]\n",
    "        out = self.meta(inp)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Ap6n8V6DLhvY"
   },
   "outputs": [],
   "source": [
    "def calculate_criterion(trg, out, criterion):\n",
    "    s = 0\n",
    "    for ind, i in enumerate(out):\n",
    "        s += criterion(i, trg[ind].view(-1)) / len(trg)\n",
    "    return s\n",
    "\n",
    "def train(model, train_src, train_trg,\n",
    "          batch_size,\n",
    "          criterion,\n",
    "          clip,\n",
    "          device,\n",
    "          train_history=None,\n",
    "          valid_history=None):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    history = []\n",
    "    indexes = [i for i in range(len(train_src[0]))]\n",
    "    indexes = np.random.permutation(indexes)\n",
    "    indexes = np.array_split(indexes, len(indexes) // batch_size)\n",
    "    \n",
    "    optimizer_char = optim.Adam(model.char_model.parameters(), lr=1e-3)\n",
    "    optimizer_words = optim.Adam(model.word_model.parameters(), lr=1e-3)\n",
    "    optimizer_meta = optim.Adam(model.meta.parameters(), lr=1e-3)\n",
    "    \n",
    "    for i, idx in enumerate(indexes):\n",
    "        src_0 = [train_src[0][i].to(device) for i in idx]\n",
    "        src_1 = [train_src[1][i] for i in idx]\n",
    "        src_2 = [train_src[2][i].to(device) for i in idx]\n",
    "        src = (src_0, src_1, src_2)\n",
    "        trg = [train_trg[i].to(device) for i in idx]\n",
    "        \n",
    "        optimizer_char.zero_grad()\n",
    "        output = model.char_model(src[0], src[1])\n",
    "        loss = calculate_criterion(trg, output, criterion)\n",
    "        loss.backward()        \n",
    "        torch.nn.utils.clip_grad_norm_(model.char_model.parameters(), clip)\n",
    "        optimizer_char.step()\n",
    "        \n",
    "        optimizer_words.zero_grad()\n",
    "        output = model.word_model(src[2])\n",
    "        loss = calculate_criterion(trg, output, criterion)\n",
    "        loss.backward()        \n",
    "        torch.nn.utils.clip_grad_norm_(model.word_model.parameters(), clip)\n",
    "        optimizer_words.step()\n",
    "\n",
    "        optimizer_meta.zero_grad()\n",
    "        output = model(src)\n",
    "        loss = calculate_criterion(trg, output, criterion)\n",
    "        loss.backward()        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer_meta.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        history.append(loss.cpu().data.numpy())\n",
    "        if (i+1)%10==0:\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "\n",
    "            clear_output(True)\n",
    "            ax[0].plot(history, label='train loss')\n",
    "            ax[0].set_xlabel('Batch')\n",
    "            ax[0].set_title('Train loss')\n",
    "            if train_history is not None:\n",
    "                ax[1].plot(train_history, label='general train history')\n",
    "                ax[1].set_xlabel('Epoch')\n",
    "            if valid_history is not None:\n",
    "                ax[1].plot(valid_history, label='general valid history')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.show()        \n",
    "    return epoch_loss / len(indexes)\n",
    "  \n",
    "def evaluate(model, val_src, val_trg, batch_size, device, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "            indexes = [i for i in range(len(val_trg))]\n",
    "            indexes = np.random.permutation(indexes)\n",
    "            indexes = np.array_split(indexes, len(indexes) // batch_size)\n",
    "            for idx in indexes:\n",
    "                src = val_src[idx]\n",
    "                trg = val_trg[idx]\n",
    "                output = model(src)\n",
    "                output = output[1:].view(-1, output.shape[-1])\n",
    "                trg = trg[:, 1:].contiguous()\n",
    "                trg = trg.view(-1)\n",
    "                loss = criterion(output, trg)\n",
    "                epoch_loss += loss.item()\n",
    "    return epoch_loss / len(indexes)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbBC7dIabdGV"
   },
   "source": [
    "# Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vbdqNL7LfAiB",
    "outputId": "716b3c8d-db37-4496-94ca-4641b7181765"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6584"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"ru_syntagrus-ud-dev.conllu\", 'r') as f:\n",
    "    data = f.read()\n",
    "train_sentences = conllu.parse(data)\n",
    "len(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "bbCQ8zSQV7TK"
   },
   "outputs": [],
   "source": [
    "START_TOKEN = \"<\"\n",
    "END_TOKEN = \">\"\n",
    "rus_re = re.compile(r'[а-яА-ЯёЁ]+')\n",
    "def extract_sequence(sentence):\n",
    "    prev = 0\n",
    "    src_char, src_split, src_word = [], [], []\n",
    "    trg = []\n",
    "    for ind, token in enumerate(sentence):\n",
    "        if rus_re.fullmatch(token['form']):\n",
    "            new = [i for i in token['form'].lower()]\n",
    "            src_char += new\n",
    "            cur_ind = prev + len(new) - 1\n",
    "            src_split += [(prev, cur_ind)]\n",
    "            prev = cur_ind + 1\n",
    "            src_word += [token['form'].lower()]\n",
    "            trg.append(token['upos'])\n",
    "    return src_char, src_split, src_word, trg\n",
    "            \n",
    "\n",
    "def get_dataset(sentences):\n",
    "    src_char, src_split, src_word, trg = [], [], [], []\n",
    "    for sentence in sentences:\n",
    "        cur_src_char, cur_src_split, cur_src_word, cur_trg = extract_sequence(sentence)\n",
    "        src_char.append(cur_src_char)\n",
    "        src_split.append(cur_src_split)\n",
    "        src_word.append(cur_src_word)\n",
    "        trg.append(cur_trg)\n",
    "    return (src_char, src_split, src_word), trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "FwOyDXvG3h0g"
   },
   "outputs": [],
   "source": [
    "src, trg = get_dataset(train_sentences[:20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hswHynYm9EWW",
    "outputId": "3342dd02-a03d-45ca-b722-0b8b3aa83ed4"
   },
   "outputs": [],
   "source": [
    "list_of_chars = list(set().union(*[set(i) for i in src[0]]))\n",
    "mask_chars = Masking(list_of_chars, device)\n",
    "list_of_words = list(set().union(*[set(i) for i in src[2]]))\n",
    "mask_words = Masking(list_of_words, device)\n",
    "list_of_upos = list(set().union(*[set(i) for i in trg]))\n",
    "mask_upos = Masking(list_of_upos, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_0 = mask_chars.mask_batch(src[0])\n",
    "src_2 = mask_words.mask_batch(src[2])\n",
    "src = (src_0, src[1], src_2)\n",
    "trg = mask_upos.mask_batch(trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "KCZIUvIW-l9Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "emb_dim = 10\n",
    "hid_dim = 10\n",
    "n_layers = 1\n",
    "out_dim = mask_upos.size_vocab\n",
    "dimensions = [128, 32]\n",
    "\n",
    "word_model = BiLSTM(mask_words.size_vocab, emb_dim, hid_dim, out_dim, n_layers,\n",
    "                 dropout=0.2,\n",
    "                 bidirectional=True, dimensions=dimensions)\n",
    "char_model = BiLSTM_char(mask_chars.size_vocab, emb_dim, hid_dim, out_dim, n_layers,\n",
    "                 dropout=0.2,\n",
    "                 bidirectional=True, dimensions=dimensions)\n",
    "meta = BiLSTM(2 * out_dim, None, hid_dim, out_dim, n_layers,\n",
    "                 dropout=0.2,\n",
    "                 bidirectional=True, dimensions=dimensions)\n",
    "model = MetaBiLSTM(char_model, word_model, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "NeDdtAbl-vTH"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "n1EsFH_Z9RNg",
    "outputId": "35541f3d-f161-4143-860f-d97714c65b5d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "train_history = []\n",
    "valid_history = []\n",
    "\n",
    "N_EPOCHS = 3\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "valid_loss = 0\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, (src[0][:-50], src[1][:-50], src[2][:-50]), trg[:-50], BATCH_SIZE, criterion, CLIP, device, train_history, valid_history)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    valid_loss = evaluate(lemmatizer, (src[0][-50:], src[1][-50:], src[2][-50:]), trg[-50:], BATCH_SIZE, device, criterion)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(lemmatizer.state_dict(), 'model.pt')\n",
    "    \n",
    "    train_history.append(train_loss)\n",
    "    valid_history.append(valid_loss)\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {np.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {np.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "id": "0QL3DmFS3RJt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_upos.size_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ABBYY_lemmatization.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
